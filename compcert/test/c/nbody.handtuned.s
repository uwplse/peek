# File generated by CompCert 2.4
# Command line: -fno-peeps -stdlib ../../runtime -dc -dclight -dasm -S -o nbody.handtuned.s nbody.c
	.section	.rodata
	.align	1
__stringlit_1:
	.ascii	"%.9f\012\000"
	.type	__stringlit_1, @object
	.size	__stringlit_1, . - __stringlit_1
	.text
	.align	16
	.globl advance
advance:
	.cfi_startproc
	subl	$84, %esp
	.cfi_adjust_cfa_offset	84
	leal	88(%esp), %edx
	movl	%edx, 8(%esp)
	movl	%ebx, 12(%esp)
	movl	%esi, 16(%esp)
	movl	%edi, 20(%esp)
	movl	%ebp, 24(%esp)
	movl	0(%edx), %edx
	movl	%edx, 36(%esp)
	movl	8(%esp), %edx
	movl	4(%edx), %edi
	movsd	8(%edx), %xmm4
	movsd	%xmm4, 40(%esp)
	xorl	%esi, %esi
.L100:
	movl	36(%esp), %edx
	cmpl	%edx, %esi
	jge	.L101
	movl	%esi, %edx
	imull	$56, %edx
	leal	0(%edi,%edx,1), %ebp
	leal	1(%esi), %ecx
	movl	%ecx, 32(%esp)
.L102:
	movl	32(%esp), %ecx
	movl	36(%esp), %eax
	cmpl	%eax, %ecx
	jge	.L103
	movl	32(%esp), %ecx
	imull	$56, %ecx
	leal	0(%edi,%ecx,1), %ebx
	movups	0(%ebp), %xmm4
	movups	0(%edi,%ecx,1), %xmm5
	subpd	%xmm5, %xmm4
	movlpd	%xmm4, 64(%esp)        
	movhpd	%xmm4, 56(%esp)
	movsd	16(%ebp), %xmm3
	movsd	16(%edi,%ecx,1), %xmm6
	subsd	%xmm6, %xmm3
	movsd	%xmm3, 48(%esp)
	mulpd	%xmm4, %xmm4	
	mulsd	%xmm3, %xmm3
	addsd	%xmm4, %xmm3
        shufpd  $0x1b, %xmm4, %xmm4
        addsd	%xmm4, %xmm3    
	movsd	%xmm3, 0(%esp)
	call	sqrt
	fstpl	72(%esp)
	movsd	72(%esp), %xmm0
	movapd	%xmm0, %xmm1
	mulsd	%xmm0, %xmm1
	mulsd	%xmm0, %xmm1
	movsd	40(%esp), %xmm6
	divsd	%xmm1, %xmm6
        #b->vx -= dx * b2->mass * mag;
	#b->vy -= dy * b2->mass * mag;
	movsd	48(%ebx), %xmm0
	movlhps %xmm0, %xmm0
        movups	56(%esp), %xmm7
        shufpd  $0x1, %xmm7, %xmm7        
        mulpd   %xmm0, %xmm7
        movlhps %xmm6, %xmm6
        mulpd   %xmm6, %xmm7
        movups	24(%ebp), %xmm1
        subpd   %xmm7, %xmm1
        movups  %xmm1, 24(%ebp)
        #b->vz -= dz * b2->mass * mag;
	movsd	40(%ebp), %xmm7	
	movsd	48(%esp), %xmm2
	mulsd	%xmm0, %xmm2
	mulsd	%xmm6, %xmm2
	subsd	%xmm2, %xmm7
	movsd	%xmm7, 40(%ebp)
        #b2->vx += dx * b->mass * mag;
	#b2->vy += dy * b->mass * mag;	
        movsd	48(%ebp), %xmm0
	movlhps %xmm0, %xmm0
	movups	56(%esp), %xmm7
	shufpd  $0x1, %xmm7, %xmm7        
	mulpd   %xmm0, %xmm7
	movlhps %xmm6, %xmm6
	mulpd   %xmm6, %xmm7
	movups	24(%ebx), %xmm1
	addpd   %xmm7, %xmm1
	movups  %xmm1, 24(%ebx)
	#b2->vz += dz * b->mass * mag;
	movsd	40(%ebx), %xmm7	
	movsd	48(%esp), %xmm2
	mulsd	%xmm0, %xmm2
	mulsd	%xmm6, %xmm2
	addsd	%xmm2, %xmm7
	movsd	%xmm7, 40(%ebx)        
        
	movl	32(%esp), %edx
	leal	1(%edx), %eax
	movl	%eax, 32(%esp)
	jmp	.L102
.L103:
	leal	1(%esi), %esi
	jmp	.L100
.L101:
	xorl	%ecx, %ecx
.L104:
	movl	36(%esp), %eax
	cmpl	%eax, %ecx
	jge	.L105
	movl	%ecx, %edx
	imull	$56, %edx

        movsd	40(%esp), %xmm0
        movlhps %xmm0, %xmm0
        #b->x += dt * b->vx;
        #b->y += dt * b->vy;
        movups	0(%edi,%edx,1), %xmm6
	movups	24(%edi,%edx,1), %xmm7
	movups   %xmm0, %xmm5
	mulpd	%xmm7, %xmm5
	addpd	%xmm5, %xmm6
	movups	%xmm6, 0(%edi,%edx,1)
        #b->z += dt * b->vz;
	movsd	16(%edi,%edx,1), %xmm6
	movsd	40(%edi,%edx,1), %xmm7
	movsd	%xmm0, %xmm5
	mulsd	%xmm7, %xmm5
	addsd	%xmm5, %xmm6
	movsd	%xmm6, 16(%edi,%edx,1)
        
	leal	1(%ecx), %ecx
	jmp	.L104
.L105:
	movl	12(%esp), %ebx
	movl	16(%esp), %esi
	movl	20(%esp), %edi
	movl	24(%esp), %ebp
	addl	$84, %esp
	ret
	.cfi_endproc
	.type	advance, @function
	.size	advance, . - advance
	.text
	.align	16
	.globl energy
energy:
	.cfi_startproc
	subl	$60, %esp
	.cfi_adjust_cfa_offset	60
	leal	64(%esp), %edx
	movl	%edx, 8(%esp)
	movl	%ebx, 12(%esp)
	movl	%esi, 16(%esp)
	movl	%edi, 20(%esp)
	movl	%ebp, 24(%esp)
	movl	0(%edx), %eax
	movl	%eax, 40(%esp)
	movl	4(%edx), %ebx
	xorpd	%xmm2, %xmm2
	movsd	%xmm2, 32(%esp)
	xorl	%esi, %esi
.L106:
	movl	40(%esp), %ecx
	cmpl	%ecx, %esi
	jge	.L107
	movl	%esi, %edx
	imull	$56, %edx
	leal	0(%ebx,%edx,1), %edi
	movsd	.L108, %xmm1 # 0.5
	movsd	48(%ebx,%edx,1), %xmm2
	mulsd	%xmm2, %xmm1
	movsd	24(%ebx,%edx,1), %xmm5
	movapd	%xmm5, %xmm3
	mulsd	%xmm5, %xmm3
	movsd	32(%ebx,%edx,1), %xmm4
	movapd	%xmm4, %xmm5
	mulsd	%xmm5, %xmm4
	addsd	%xmm4, %xmm3
	movsd	40(%ebx,%edx,1), %xmm7
	movapd	%xmm7, %xmm2
	mulsd	%xmm2, %xmm7
	addsd	%xmm7, %xmm3
	mulsd	%xmm3, %xmm1
	movsd	32(%esp), %xmm0
	addsd	%xmm1, %xmm0
	movsd	%xmm0, 32(%esp)
	leal	1(%esi), %ebp
.L109:
	movl	40(%esp), %eax
	cmpl	%eax, %ebp
	jge	.L110
	movl	%ebp, %eax
	imull	$56, %eax
	leal	0(%ebx,%eax,1), %ecx
	movl	%ecx, 44(%esp)
	movsd	0(%edi), %xmm4
	movsd	0(%ebx,%eax,1), %xmm7
	subsd	%xmm7, %xmm4
	movsd	8(%edi), %xmm6
	movsd	8(%ebx,%eax,1), %xmm3
	subsd	%xmm3, %xmm6
	movsd	16(%edi), %xmm7
	movsd	16(%ebx,%eax,1), %xmm5
	subsd	%xmm5, %xmm7
	mulsd	%xmm4, %xmm4
	mulsd	%xmm6, %xmm6
	addsd	%xmm6, %xmm4
	mulsd	%xmm7, %xmm7
	addsd	%xmm7, %xmm4
	movsd	%xmm4, 0(%esp)
	call	sqrt
	fstpl	48(%esp)
	movsd	48(%esp), %xmm2
	movsd	48(%edi), %xmm3
	movl	44(%esp), %edx
	movsd	48(%edx), %xmm1
	mulsd	%xmm1, %xmm3
	divsd	%xmm2, %xmm3
	movsd	32(%esp), %xmm1
	subsd	%xmm3, %xmm1
	movsd	%xmm1, 32(%esp)
	leal	1(%ebp), %ebp
	jmp	.L109
.L110:
	leal	1(%esi), %esi
	jmp	.L106
.L107:
	fldl	32(%esp)
	movl	12(%esp), %ebx
	movl	16(%esp), %esi
	movl	20(%esp), %edi
	movl	24(%esp), %ebp
	addl	$60, %esp
	ret
	.cfi_endproc
	.type	energy, @function
	.size	energy, . - energy
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L108:	.quad	0x3fe0000000000000
	.text
	.align	16
	.globl offset_momentum
offset_momentum:
	.cfi_startproc
	subl	$20, %esp
	.cfi_adjust_cfa_offset	20
	leal	24(%esp), %edx
	movl	%edx, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%esi, 8(%esp)
	movl	0(%edx), %ebx
	movl	4(%edx), %esi
	xorpd	%xmm0, %xmm0
	movapd	%xmm0, %xmm1
	movapd	%xmm1, %xmm4
	xorl	%ecx, %ecx
.L111:
	cmpl	%ebx, %ecx
	jge	.L112
	movl	%ecx, %eax
	imull	$56, %eax
	movsd	24(%esi,%eax,1), %xmm2
	movsd	48(%esi,%eax,1), %xmm6
	mulsd	%xmm6, %xmm2
	addsd	%xmm2, %xmm0
	movsd	32(%esi,%eax,1), %xmm7
	mulsd	%xmm6, %xmm7
	addsd	%xmm7, %xmm1
	movsd	40(%esi,%eax,1), %xmm5
	mulsd	%xmm6, %xmm5
	addsd	%xmm5, %xmm4
	leal	1(%ecx), %ecx
	jmp	.L111
.L112:
	xorpd	__negd_mask, %xmm0
	movsd	.L113, %xmm3 # 39.478417604357432
	divsd	%xmm3, %xmm0
	movsd	%xmm0, 24(%esi)
	xorpd	__negd_mask, %xmm1
	divsd	%xmm3, %xmm1
	movsd	%xmm1, 32(%esi)
	xorpd	__negd_mask, %xmm4
	divsd	%xmm3, %xmm4
	movsd	%xmm4, 40(%esi)
	movl	4(%esp), %ebx
	movl	8(%esp), %esi
	addl	$20, %esp
	ret
	.cfi_endproc
	.type	offset_momentum, @function
	.size	offset_momentum, . - offset_momentum
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L113:	.quad	0x4043bd3cc9be45de
	.data
	.align	4
	.global	bodies
bodies:
	.quad	0 # 0
	.quad	0 # 0
	.quad	0 # 0
	.quad	0 # 0
	.quad	0 # 0
	.quad	0 # 0
	.quad	4607182418800017408 # 1
	.quad	4617136985637443884 # 4.8414314424647209
	.quad	-4615467600764216452 # -1.16032004402742839
	.quad	-4631240860977730576 # -0.103622044471123109
	.quad	4565298575141802505 # 0.00166007664274403694
	.quad	4575526377712152758 # 0.00769901118419740425
	.quad	-4678648916774830720 # -6.90460016972063023e-05
	.quad	4561945624537448757 # 0.000954791938424326609
	.quad	4620886515960171111 # 8.34336671824457987
	.quad	4616330128746480048 # 4.12479856412430479
	.quad	-4622431185293064580 # -0.403523417114321381
	.quad	-4654844366491345546 # -0.00276742510726862411
	.quad	4572412932590500024 # 0.00499852801234917238
	.quad	4537421943404317376 # 2.30417297573763929e-05
	.quad	4553909289163810552 # 0.000285885980666130812
	.quad	4623448502799161807 # 12.894369562139131
	.quad	-4598675596822288770 # -15.1111514016986312
	.quad	-4626158513131520608 # -0.223307578892655734
	.quad	4568982327883454804 # 0.00296460137564761618
	.quad	4567630804959669473 # 0.0023784717395948095
	.quad	-4683997032734786912 # -2.96589568540237556e-05
	.quad	4541568263676574678 # 4.36624404335156298e-05
	.quad	4624847617829197610 # 15.3796971148509165
	.quad	-4595383180696444384 # -25.9193146099879641
	.quad	4595626498235032896 # 0.179258772950371181
	.quad	4568327644518236960 # 0.00268067772490389322
	.quad	4565151762383216008 # 0.00162824170038242295
	.quad	-4676722100952656048 # -9.5159225451971587e-05
	.quad	4542726933152861932 # 5.15138902046611451e-05
	.type	bodies, @object
	.size	bodies, . - bodies
	.text
	.align	16
	.globl setup_bodies
setup_bodies:
	.cfi_startproc
	subl	$12, %esp
	.cfi_adjust_cfa_offset	12
	leal	16(%esp), %edx
	movl	%edx, 0(%esp)
	xorl	%ecx, %ecx
.L114:
	movl	%ecx, %eax
	imull	$56, %eax
	movsd	(bodies + 24)(%eax), %xmm1
	movsd	.L115, %xmm0 # 365.240000000000009
	mulsd	%xmm0, %xmm1
	movsd	%xmm1, (bodies + 24)(%eax)
	movsd	(bodies + 32)(%eax), %xmm3
	mulsd	%xmm0, %xmm3
	movsd	%xmm3, (bodies + 32)(%eax)
	movsd	(bodies + 40)(%eax), %xmm2
	mulsd	%xmm0, %xmm2
	movsd	%xmm2, (bodies + 40)(%eax)
	movsd	(bodies + 48)(%eax), %xmm4
	movsd	.L116, %xmm5 # 39.478417604357432
	mulsd	%xmm5, %xmm4
	movsd	%xmm4, (bodies + 48)(%eax)
	leal	1(%ecx), %ecx
	cmpl	$5, %ecx
	jl	.L114
	addl	$12, %esp
	ret
	.cfi_endproc
	.type	setup_bodies, @function
	.size	setup_bodies, . - setup_bodies
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L116:	.quad	0x4043bd3cc9be45de
.L115:	.quad	0x4076d3d70a3d70a4
	.text
	.align	16
	.globl main
main:
	.cfi_startproc
	subl	$44, %esp
	.cfi_adjust_cfa_offset	44
	leal	48(%esp), %edx
	movl	%edx, 16(%esp)
	movl	%ebx, 20(%esp)
	movl	%esi, 24(%esp)
	movl	0(%edx), %ecx
	movl	4(%edx), %eax
	cmpl	$2, %ecx
	jl	.L117
	movl	4(%eax), %eax
	movl	%eax, 0(%esp)
	call	atoi
	jmp	.L118
.L117:
	movl	$20000000, %eax
.L118:
	movl	%eax, %ebx
	call	setup_bodies
	movl	$5, %ecx
	leal	bodies, %eax
	movl	%ecx, 0(%esp)
	movl	%eax, 4(%esp)
	call	offset_momentum
	movl	$5, %ecx
	leal	bodies, %edx
	movl	%ecx, 0(%esp)
	movl	%edx, 4(%esp)
	call	energy
	fstpl	32(%esp)
	movsd	32(%esp), %xmm2
	leal	__stringlit_1, %ecx
	movl	%ecx, 0(%esp)
	movsd	%xmm2, 4(%esp)
	call	printf
	movl	$1, %esi
.L119:
	cmpl	%ebx, %esi
	jg	.L120
	movl	$5, %edx
	leal	bodies, %ecx
	movsd	.L121, %xmm0 # 0.0100000000000000002
	movl	%edx, 0(%esp)
	movl	%ecx, 4(%esp)
	movsd	%xmm0, 8(%esp)
	call	advance
	leal	1(%esi), %esi
	jmp	.L119
.L120:
	movl	$5, %eax
	leal	bodies, %edx
	movl	%eax, 0(%esp)
	movl	%edx, 4(%esp)
	call	energy
	fstpl	32(%esp)
	movsd	32(%esp), %xmm1
	leal	__stringlit_1, %edx
	movl	%edx, 0(%esp)
	movsd	%xmm1, 4(%esp)
	call	printf
	xorl	%eax, %eax
	movl	20(%esp), %ebx
	movl	24(%esp), %esi
	addl	$44, %esp
	ret
	.cfi_endproc
	.type	main, @function
	.size	main, . - main
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L121:	.quad	0x3f847ae147ae147b
	.section	.rodata
	.align	16
__negd_mask:	.quad   0x8000000000000000, 0
__absd_mask:	.quad   0x7FFFFFFFFFFFFFFF, 0xFFFFFFFFFFFFFFFF
__negs_mask:	.long   0x80000000, 0, 0, 0
__abss_mask:	.long   0x7FFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF
